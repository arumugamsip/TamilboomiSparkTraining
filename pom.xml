<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>
  <groupId>aru</groupId>
  <artifactId>aru</artifactId>
  <version>0.0.1-SNAPSHOT</version>
  
  <properties>
		<maven.compiler.source>1.8</maven.compiler.source>
		<maven.compiler.target>1.8</maven.compiler.target>
		<encoding>UTF-8</encoding>
		<scala.version>2.11.8</scala.version>
		<scala.compat.version>2.11</scala.compat.version>
	</properties>

	<dependencies>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_2.11</artifactId>
			<version>2.1.1</version>
			<scope>compile</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-sql_2.11</artifactId>
			<version>2.1.1</version>
			<scope>compile</scope>
		</dependency>
		<!-- https://mvnrepository.com/artifact/org.apache.spark/spark-mllib -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-mllib_2.11</artifactId>
			<version>2.1.1</version>
		</dependency>

		<dependency>
			<groupId>org.slf4j</groupId>
			<artifactId>slf4j-api</artifactId>
			<version>1.7.5</version>
		</dependency>
		<dependency>
			<groupId>org.slf4j</groupId>
			<artifactId>slf4j-log4j12</artifactId>
			<version>1.7.25</version>
		</dependency>
		<dependency>
			<groupId>org.clapper</groupId>
			<artifactId>grizzled-slf4j_2.11</artifactId>
			<version>1.3.1</version>
		</dependency>
		<dependency>
			<groupId>org.slf4j</groupId>
			<artifactId>slf4j-log4j12</artifactId>
			<version>1.7.25</version>
		</dependency>
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-library</artifactId>
			<version>2.11.8</version>
		</dependency>
		<!-- Test -->
		<dependency>
			<groupId>junit</groupId>
			<artifactId>junit</artifactId>
			<version>4.11</version>
			<scope>test</scope>
		</dependency>
	</dependencies>

	<build>
		<sourceDirectory>src/main/scala</sourceDirectory>
		<testSourceDirectory>src/test/scala</testSourceDirectory>
		<plugins>
			<plugin>
				<!-- see http://davidb.github.com/scala-maven-plugin -->
				<groupId>net.alchim31.maven</groupId>
				<artifactId>scala-maven-plugin</artifactId>
				<version>3.3.1</version>
				<executions>
					<execution>
						<goals>
							<goal>compile</goal>
							<goal>testCompile</goal>
						</goals>
						<configuration>
							<args>
								<arg>-feature</arg>
								<arg>-deprecation</arg>
								<arg>-dependencyfile</arg>
								<arg>${project.build.directory}/.scala_dependencies</arg>
							</args>
						</configuration>
					</execution>
				</executions>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-surefire-plugin</artifactId>
				<version>2.18.1</version>
				<configuration>
					<useFile>false</useFile>
					<disableXmlReport>true</disableXmlReport>
					<!-- If you have classpath issue like NoDefClassError,... -->
					<!-- useManifestOnlyJar>false</useManifestOnlyJar -->
					<includes>
						<include>**/*Test.*</include>
						<include>**/*Suite.*</include>
					</includes>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.codehaus.mojo</groupId>
				<artifactId>exec-maven-plugin</artifactId>
				<version>1.5.0</version>
				<executions>
					<execution>
						<id>run-local</id>
						<goals>
							<goal>exec</goal>
						</goals>
						<configuration>
							<executable>spark-submit</executable>
							<arguments>
								<argument>--master</argument>
								<argument>local</argument>
								<argument>${project.build.directory}/${project.artifactId}-${project.version}-uber.jar</argument>
							</arguments>
						</configuration>
					</execution>
					<execution>
						<id>run-yarn</id>
						<goals>
							<goal>exec</goal>
						</goals>
						<configuration>
							<environmentVariables>
								<HADOOP_CONF_DIR>
									${basedir}/spark-remote/conf
								</HADOOP_CONF_DIR>
							</environmentVariables>
							<executable>spark-submit</executable>
							<arguments>
								<argument>--master</argument>
								<argument>yarn</argument>
								<argument>${project.build.directory}/${project.artifactId}-${project.version}.jar</argument>
							</arguments>
						</configuration>
					</execution>
				</executions>
			</plugin>
			<!-- Use the shade plugin to remove all the provided artifacts (such as 
				spark itself) from the uber jar -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-shade-plugin</artifactId>
				<version>3.1.0</version>
				<executions>
					<execution>
						<phase>package</phase>
						<goals>
							<goal>shade</goal>
						</goals>
						<configuration>
							<!-- Remove signed keys to prevent security exceptions on uber jar -->
							<!-- See https://stackoverflow.com/a/6743609/7245239 -->
							<filters>
								<filter>
									<artifact>*:*</artifact>
									<excludes>
										<exclude>META-INF/*.SF</exclude>
										<exclude>META-INF/*.DSA</exclude>
										<exclude>META-INF/*.RSA</exclude>
									</excludes>
								</filter>
							</filters>
							<transformers>
								<transformer
									implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">
									<manifestEntries>
										<Main-Class>aru.aru.test</Main-Class>
									</manifestEntries>
								</transformer>
							</transformers>
							<artifactSet>
								<excludes>
									<exclude>javax.servlet:*</exclude>
									<exclude>org.apache.hadoop:*</exclude>
									<exclude>org.apache.maven.plugins:*</exclude>
									<exclude>org.apache.spark:*</exclude>
									<exclude>org.apache.avro:*</exclude>
									<exclude>org.apache.parquet:*</exclude>
									<exclude>org.scala-lang:*</exclude>
								</excludes>
							</artifactSet>
							<finalName>${project.artifactId}-${project.version}-uber</finalName>
						</configuration>
					</execution>
				</executions>
			</plugin>
		</plugins>
	</build>
</project>